{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unlikely-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import pandas as pd \n",
    "import itertools\n",
    "import numpy as np\n",
    "from symspellpy.symspellpy import SymSpell, Verbosity\n",
    "import pkg_resources\n",
    "from spellchecker import SpellChecker\n",
    "import html\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8862ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0461e",
   "metadata": {},
   "source": [
    "## hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39730e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check_words(word):\n",
    "    # lookup suggestions for multi word string input\n",
    "    spell = SymSpell(max_dictionary_edit_distance=3, prefix_length=7)\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    bigram_path = pkg_resources.resource_filename(\n",
    "    \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
    "    spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    spell.load_bigram_dictionary(bigram_path, term_index=0, count_index=2)\n",
    "    suggestions = spell.lookup_compound(input_term, max_edit_distance=2)\n",
    "# display suggestion term, edit distance, and term frequency\n",
    "    for suggestion in suggestions:\n",
    "        print(suggestion)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "162d8088",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spell_check_word(word):\n",
    "    # lookup suggestions for individual words\n",
    "    spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=5)\n",
    "    dictionary_path = pkg_resources.resource_filename(\n",
    "                      \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
    "    spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    corrections = spell.lookup(word, Verbosity.TOP)\n",
    "    for correction in corrections:\n",
    "        print(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4408dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions related to expanded hashtags in text\n",
    "def pascal_case_split(text):\n",
    "    # expand hashtags formatted in pascal case, ex: #ThisIsPascal\n",
    "    return re.sub(r'([A-Z])([?=a-z0-9+])', r' \\1\\2', text)\n",
    "\n",
    "def camel_case_split(text):\n",
    "    # expand hashtags formatted in pascal case, ex: #thisIsCamel\n",
    "    return re.sub(r'([a-z0-9+])([?<=A-Z])', r'\\1 \\2', text)\n",
    "\n",
    "def remove_hash(text):\n",
    "    # remove hash symbol in front of hashtag text and remove non unicode chars\n",
    "    return re.sub('#', '', text)\n",
    "\n",
    "\n",
    "def remove_non_alpha(text):\n",
    "    # function to remove non unicode characters from string\n",
    "    return re.sub('[^a-zA-Z_, ]', '', text)\n",
    "\n",
    "        \n",
    "def expand_hashtags(text):\n",
    "    # combine hashtag split functions for specific cases and remove hash\n",
    "    c_text = camel_case_split(text)\n",
    "    p_text = pascal_case_split(c_text)\n",
    "    lu_text = desegment_hashtag(p_text)\n",
    "    h_text = remove_hash(lu_text)\n",
    "    return html.unescape(h_text)\n",
    "\n",
    "def desegment_hashtag(text):\n",
    "    spell = SymSpell(max_dictionary_edit_distance=0, prefix_length=7)\n",
    "    dictionary_path = pkg_resources.resource_filename(\"symspellpy\",\"frequency_dictionary_en_82_765.txt\")\n",
    "    spell.load_dictionary(dictionary_path, term_index=0, count_index=1)\n",
    "    if text.isupper() | text.islower() and len(text)>= 15:\n",
    "        result = spell.word_segmentation(text)\n",
    "        text = result.corrected_string\n",
    "    return text\n",
    "\n",
    "def monocase_mask(text):\n",
    "    # returns boolean mask for monocase strings \n",
    "    if text.isupper() | text.islower() and text != 'nan':\n",
    "        return True\n",
    "\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def mono_check(text):\n",
    "    # returns boolean mask for monocase strings \n",
    "    text.isupper() | text.islower() and text != 'nan'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4299daf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column for extracted hashtags\n",
    "df['hashtags'] = df.text.str.findall(r'(?:(?<=\\s)|(?<=^))#.*?(?=\\s|$)')\n",
    "df.hashtags = df.hashtags.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3560bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_hashtags = df.hashtags.apply(lambda x: (expand_hashtags(x)))\n",
    "df['expanded_hashtags'] = expanded_hashtags.str.strip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
